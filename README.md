# Teste T√©cnico Intuitive Care - Mateus Marinho

Este reposit√≥rio cont√©m a solu√ß√£o completa para o Teste T√©cnico da Intuitive Care (v2.0), abrangendo todas as 4 fases do desafio: Integra√ß√£o com API, Transforma√ß√£o de Dados, Banco de Dados e Interface Web.

## üìÅ Estrutura do Projeto

*   `teste_api_ans/`: Scripts da Fase 1 (Download e processamento API ANS).
*   `teste_transformacao_validacao/`: Scripts da Fase 2 (Limpeza e enriquecimento de dados).
*   `teste_banco_dados/`: Scripts SQL da Fase 3 (Schemas e Queries).
*   `teste_api_interface/`: Aplica√ß√£o Web da Fase 4 (Backend FastAPI + Frontend Vue.js).
*   `data/`: Diret√≥rio de armazenamento de dados brutos e processados (alguns arquivos grandes podem n√£o estar no Git).
*   `README.md`: Este arquivo de documenta√ß√£o.

---

## üöÄ Como Executar

O projeto foi desenvolvido em ambiente Windows, utilizando Python 3, Node.js (v18+) e MySQL 8.0.

### Pr√©-requisitos
*   Python 3.10+
*   Node.js & NPM
*   MySQL Server 8.0
*   Git

### Passo 1: Integra√ß√£o API e Dados (Fases 1 e 2)

Execute os scripts Python sequencialmente para baixar e preparar os dados:

```bash
# 1. Download e Processamento Inicial
python teste_api_ans/download_ans_demos.py
python teste_api_ans/process_ans_files.py
python teste_api_ans/consolidate_ans_expenses.py

# 2. Transforma√ß√£o e Valida√ß√£o
python teste_transformacao_validacao/run_transformation.py
```

Isso gerar√° os arquivos CSV finais em `teste_transformacao_validacao/` e `data/processed/`.

### Passo 2: Banco de Dados (Fase 3)

1.  Acesse seu MySQL Client (Workbench, DBeaver ou CLI).
2.  Execute os scripts na ordem:
    *   `teste_banco_dados/01_schema_mysql.sql`: Cria o banco e tabelas.
    *   `teste_banco_dados/03_import_mysql.sql`: Importa os dados dos CSVs gerados (ajuste os caminhos nos comandos `LOAD DATA` se necess√°rio).
    *   `teste_banco_dados/04_queries_mysql.sql`: Executa as queries anal√≠ticas solicitadas.

> **Nota caso use CLI:** Certifique-se de habilitar `local-infile=1` no cliente e servidor MySQL para permitir a importa√ß√£o de CSVs locais.

### Passo 3: Interface Web (Fase 4)

A aplica√ß√£o √© composta por um Backend (FastAPI) e Frontend (Vue.js).

**Backend:**
```bash
cd teste_api_interface/backend
pip install -r requirements.txt
# Configure o .env se necess√°rio (DB_PASSWORD, etc)
python main.py
# Servidor rodar√° em http://localhost:8000
```

**Frontend:**
```bash
cd teste_api_interface/frontend
npm install
npm run dev
# Acesse em http://localhost:5173
```

---

## ‚öñÔ∏è Trade-offs T√©cnicos e Decis√µes de Arquitetura

Conforme solicitado, abaixo est√£o documentadas as decis√µes t√©cnicas tomadas para cada desafio do teste.

### Fase 1: Processamento de Arquivos
*   **Mem√≥ria vs Incremental:** Optei pelo **processamento incremental**. Dado que os arquivos da ANS podem ser grandes e hist√≥ricos (v√°rios anos/trimestres), carregar tudo em mem√≥ria Pandas poderia estourar a RAM em ambientes menores. Processar arquivo por arquivo e fazer *append* no resultado final √© mais seguro e escal√°vel.

### Fase 2: Valida√ß√£o e Enriquecimento
*   **Tratamento de CNPJs Inv√°lidos:** Optei por **segregar os dados**. Linhas com CNPJs inv√°lidos ou nulos n√£o s√£o descartadas silenciosamente, mas tamb√©m n√£o poluem a base principal. Elas podem ser logadas ou salvas em um arquivo de "rejeitados" (como implementado no script de importa√ß√£o do banco), permitindo auditoria posterior sem comprometer a integridade das an√°lises.
*   **Estrat√©gia de Join:** Utilizei a biblioteca **Pandas (`merge`)**. Para o volume de dados atual (milhares de operadoras), o Pandas √© extremamente eficiente e pr√°tico, permitindo joins em mem√≥ria r√°pidos. Se o volume fosse na casa dos Terabytes, mudaria para PySpark ou Dask.
*   **Ordena√ß√£o:** A ordena√ß√£o foi feita via Pandas `sort_values`. √â r√°pido e suficiente para datasets que cabem na mem√≥ria.

### Fase 3: Banco de Dados
*   **Normaliza√ß√£o:** Escolhi uma abordagem **h√≠brida (levemente desnormalizada)** para as despesas.
    *   `operadoras`: Tabela cadastral normalizada (chave: registro_operadora/cnpj).
    *   `consolidado_despesas`: Mantida separada para evitar duplica√ß√£o de dados cadastrais a cada linha de despesa. Contudo, mantive `razao_social` nela temporariamente para facilitar queries r√°pidas de leitura humana, embora a boa pr√°tica estrita de 3NF sugerisse usar apenas o ID da operadora.
*   **Tipos de Dados:**
    *   **Monet√°rios (`DECIMAL(18,2)`):** Imprescind√≠vel para valores financeiros para evitar erros de arredondamento de ponto flutuante (comuns em `FLOAT`).
    *   **Datas:** Utilizei `DATE` para campos de data completa e `INT`/`SMALLINT` para Ano/Trimestre, facilitando indexa√ß√£o e buscas por per√≠odo.

### Fase 4: API e Interface
*   **Backend Framework (FastAPI vs Flask):** Escolhi **FastAPI**.
    *   *Justificativa:* Performance superior (ASGI), valida√ß√£o de dados nativa com Pydantic (reduz c√≥digo de boilerplate) e gera√ß√£o autom√°tica de documenta√ß√£o (Swagger UI), o que acelera muito o desenvolvimento e teste.
*   **Pagina√ß√£o (Offset vs Cursor):** Escolhi **Offset-based (`page` e `limit`)**.
    *   *Justificativa:* √â mais intuitivo para o usu√°rio final em interfaces de tabelas ("Ir para p√°gina 5"). Cursor-based √© melhor para performance em *scroll infinito* ou volumes massivos, mas para uma lista administrativa de ~1000 - ~2000 registros, Offset √© perfeitamente adequado e mais simples de implementar no frontend.
*   **Cache:** Implementa√ß√£o planejada via **Cache Simples em Mem√≥ria (opcional)** ou banco.
    *   Para `/api/estatisticas`: Como s√£o queries pesadas de agrega√ß√£o, o ideal em produ√ß√£o √© cachear por X minutos (ex: Redis) ou usar uma Materialized View no banco. No escopo deste teste, as queries s√£o r√°pidas o suficiente para serem executadas em tempo real.
*   **Resposta da API:** Optei por **Dados + Metadados**.
    *   Ex: `{ "data": [...], "total": 100, "page": 1, "limit": 10 }`. Isso permite que o Frontend monte os componentes de pagina√ß√£o (n√∫mero total de p√°ginas) sem precisar fazer uma request separada.
*   **Busca no Frontend:** Optei por **Busca no Servidor**.
    *   *Justificativa:* Embora 1000 operadoras caibam na mem√≥ria do navegador, realizar a filtragem no backend (SQL `LIKE` ou Full Text Search) √© mais robusto, economiza banda (n√£o precisa baixar tudo de uma vez) e j√° prepara a aplica√ß√£o para escalar quando houver milh√µes de registros.
*   **Gerenciamento de Estado (Pinia):** Usei **Pinia** (padr√£o atual do Vue 3).
    *   Centraliza o estado das operadoras e pagina√ß√£o, facilitando a comunica√ß√£o entre a lista, a barra de busca e a pagina√ß√£o sem "prop drilling" excessivo.

## üìö Documenta√ß√£o da API

A documenta√ß√£o interativa (Swagger UI) est√° dispon√≠vel em `/docs` quando o backend est√° rodando.
Al√©m disso, uma **Postman Collection** (`postman_collection.json`) est√° inclu√≠da na raiz do projeto para testes externos.

---
## üß™ Testes Automatizados (Diferencial)

Foi implementada uma su√≠te de testes unit√°rios para o Backend, garantindo a integridade dos principais endpoints e regras de neg√≥cio.

Para executar:
```bash
cd teste_api_interface/backend
# Instale as depend√™ncias de teste
pip install pytest httpx
# Execute os testes
python -m pytest test_main.py
```
O resultado deve exibir `5 passed`, cobrindo:
1. Health Check
2. Listagem Paginada
3. Busca V√°lida
4. Tratamento de Erro (404)
5. Estat√≠sticas Consolidadas

---
**Desenvolvido por Mateus Marinho**
